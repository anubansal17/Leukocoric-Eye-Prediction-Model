{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evaluation data', 'SampleSubmission.csv', 'train data']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f2e1fb16285387227703770fc5dfe7fa5beb0476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape =(128, 128, 3), activation = 'relu'))\n",
    "#Step2-Max Pooling(Size of resulting matrix after applying max pooling is (Size of feature map)/2\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Convolution2D(32, (3, 3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#Step3-Flattening\n",
    "classifier.add(Flatten())\n",
    "#Step4-Full Connection\n",
    "classifier.add(Dense(activation=\"relu\", units=128))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9378ba339c9a362c455dd05e726463ba9f97578e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 885 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "885/885 [==============================] - 142s 160ms/step - loss: 0.1698 - acc: 0.9328\n",
      "Epoch 2/20\n",
      "885/885 [==============================] - 141s 160ms/step - loss: 0.0324 - acc: 0.9887\n",
      "Epoch 3/20\n",
      "885/885 [==============================] - 139s 158ms/step - loss: 0.0216 - acc: 0.9933\n",
      "Epoch 4/20\n",
      "885/885 [==============================] - 140s 158ms/step - loss: 0.0152 - acc: 0.9955\n",
      "Epoch 5/20\n",
      "885/885 [==============================] - 139s 157ms/step - loss: 0.0195 - acc: 0.9941\n",
      "Epoch 6/20\n",
      "885/885 [==============================] - 141s 159ms/step - loss: 0.0130 - acc: 0.9960\n",
      "Epoch 7/20\n",
      "885/885 [==============================] - 140s 158ms/step - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 8/20\n",
      "288/885 [========>.....................] - ETA: 1:32 - loss: 0.0188 - acc: 0.9945"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(   '../input/train data/Train data',\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=885,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4478327918a26ecca750e89172cb5c8b0bad50a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "result = []\n",
    "for i in range(0, 200):\n",
    "    test_image = image.load_img('../input/evaluation data/Evaluation data/'+str(i)+'.jpg', target_size = (128, 128))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    pred = int(classifier.predict(test_image))\n",
    "    if pred == 0 :\n",
    "        pred = 1\n",
    "    else :\n",
    "        pred = 0\n",
    "    result.append(pred) \n",
    "result = np.array(result)\n",
    "print(result)\n",
    "np.size(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "678981c673f4930240e8a3d22e3c34e4024b5d49"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(result).to_csv(\"../file3.csv\",header = 'category', index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
